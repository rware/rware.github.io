{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Wrangling in Python\n",
    "-----------------------------------------\n",
    "By: Ranysha Ware (<rwjanee@gmail.com>)\n",
    "\n",
    "Machine learning algorithms require data. In the age of information, there are many options to aquire a lot of data for free. Today, we're going to review some ways you can gather data on the Web using Python by gathering data to answer the question: **What new 2016 shows should I watch this fall**?\n",
    "\n",
    "The outline of today's lecture is as follows:\n",
    "  1. 5 Minute Intro: Python\n",
    "  2. 5 Minute Intro: How The Internet Works\n",
    "  3. Relevant Python packages \n",
    "  4. How to access data via a public API\n",
    "  5. Scraping Wikipedia TV data\n",
    "  6. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Minute Intro: Python\n",
    "-------------------------------\n",
    "Python is a [dynamically typed](https://en.wikipedia.org/wiki/Type_system#Dynamic_type_checking_and_runtime_type_information) [interpreted language](https://en.wikipedia.org/wiki/Interpreted_language). \n",
    "\n",
    "There are two supported versions of Python, Python 2.7 and Python 3. Use the latest version of Python 3.  The code in this lecture has been tested with Python 3.5.\n",
    "\n",
    "**Everything in Python is an object.** Objects have attributes and methods.  Attributes are key-value pairs.  Methods are functions, usually used to modify the object.  \n",
    "\n",
    "Some useful builtin objects include: <br>\n",
    "`None` - null object <br>\n",
    "`int` - a whole number <br>\n",
    "`float` - a floating point number <br>\n",
    "`string` - a sequence of characters <br>\n",
    "`list` - a mutable sequence of objects <br>\n",
    "`tuple` - an immutable sequence of objects <br>\n",
    "`set` - a mutable group of data <br>\n",
    "`dict` - a mutable set of key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example = {\n",
    "    \"hey i'm a dictionary key\" : \"and here's my value\",\n",
    "    \"here's another value\" : [1,2,3,4],\n",
    "    10 : (1,2),\n",
    "    'a' : None \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"hey i'm a dictionary key\": \"and here's my value\",\n",
       " 10: (1, 2),\n",
       " \"here's another value\": [1, 2, 3, 4],\n",
       " 'a': 'new value'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['a'] = 'new value'\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"hey i'm a dictionary key\": \"and here's my value\",\n",
       " 10: (1, 2),\n",
       " \"here's another value\": [1, 2, 3, 4, 5],\n",
       " 'a': 'new value'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"here's another value\"].append(5)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even functions are just objects that contain some code to run when you call them.  Functions are defined with the `def` keyword. By default, all functions return `None`. You can change the value returned with the `return` keyword.\n",
    "\n",
    "Other useful language constructs include `for` loops and list comprehensions. In addition, to use packages you can import them into your current project with the `import` keyword.\n",
    "\n",
    "We'll see illustrative examples of functions, loops, comprehensions, and imports later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Minute Intro: How The Internet Works\n",
    "-----------------------------------------------------\n",
    "You all interact with the Internet via the World Wide Web typically through a web browser.  When communicating over the Web, your browser (or computer) is acting as a *client*.  **Clients send and recieve some data to and from a *server**.  **A server recieves requests from clients and sends back some data.** The way clients and servers communicate is via some well-defined *protocol*. **A protocol is a set of rules for how clients and servers should exchange messages.**\n",
    "\n",
    "The protocol we'll be using to gather data is *HTTP*. (Don't worry what that actually stands for, it *really* doesn't matter).  Everytime you type a website address into your browser and press enter, you are sending one or more HTTP requests to an HTTP server.  The HTTP server will send you back some data.  In the case of web browsing, this data is typically some *HTML* string that your browser will use to render the website you're trying to visit.\n",
    "\n",
    "[comment]: <> (HTML consists of a series of tags that can tell a web browser how to render the text and images. While HTML and HTTP alone were sufficient for sharing data over the internet in the beginning, in today's \"application-centric\" world, many developers want to be able to receive data from )\n",
    "\n",
    "[comment]: <> (Note, there are way more protocols that make the internet work than just HTTP, but those are beyond the scope of this lecture.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages We'll Need\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests` will let us send HTTP requests to an HTTP server, and recieve the response without worrying about the low-level details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Terms of Use - Wikimedia Foundation</title>\n",
      "<script>document.documentElement.className = document.d\n"
     ]
    }
   ],
   "source": [
    "# send request to get the Wikipedia Terms of Use\n",
    "response = requests.get(\n",
    "    'https://wikimediafoundation.org/wiki/Terms_of_Use')\n",
    "# this will throw an assertion error if the response is an error\n",
    "assert(response.ok)\n",
    "# print the first 200 characters of the text of the response\n",
    "print(response.text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup   # use from keyword to import sub-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `bs4` (BeautifulSoup 4) package to search HTML text we get back in an HTML response. This way we can extract the parts of the web page we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>In other languages</b>,\n",
       " <b><strong class=\"selflink\">English</strong></b>,\n",
       " <b>This is a summary of the Terms of Use.  To read the full terms, scroll down or <a href=\"/wiki/Terms_of_Use#Our_Terms_of_Use\" title=\"Terms of Use\">click here</a>.</b>,\n",
       " <b>summary</b>,\n",
       " <b>Part of our mission is to</b>,\n",
       " <b>Empower and Engage</b>,\n",
       " <b>Disseminate</b>,\n",
       " <b>You are free to</b>,\n",
       " <b>Read and Print</b>,\n",
       " <b>Share and Reuse</b>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the html text\n",
    "parser = BeautifulSoup(response.text, 'html.parser')\n",
    "# find all the <b> tags\n",
    "bold_text = parser.find_all('b')\n",
    "# display the first 10 tags\n",
    "bold_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions for searching strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>In other languages</b>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use regex to find all bold tags that contain the string 'language'\n",
    "parser.find_all('b', text=re.compile('languages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames similar to data frames in `R`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Wikipedia TV Data\n",
    "---------------------------------------\n",
    "### Some General Web Scraping Rules\n",
    "- *First, read the terms of service.* Unfortunately, many websites explicitly forbid web scraping of any kind. Examples: [Craigslist](https://www.craigslist.org/about/terms.of.use.en)\n",
    "- *Prefer an API.* Websites with lots of data that they are willing to share, will typically expose a special API for requesting data.  These are typically REST API's that will return data in nicely formatted JSON that is easier to parse than HTML. \n",
    "- *Obey rate limits and authentication requirements.* You'll get blocked if you don't.\n",
    "- *Anticipate errors.* The format of websites is not monolithic. Always be prepared to handle the erros that will inevitable occur.\n",
    "- *Validate assumptions about data after scraping.*  Ensure fields that are suppose to be non-null actually are.  Ensure fields you expect to be numbers actually are all numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikimedia API\n",
    "\n",
    "[comment]: <> (need to add information here about why we prefer wikimedia to calling requests to render the pages we want directly)\n",
    "\n",
    "Documentation: https://www.mediawiki.org/wiki/API:Main_page\n",
    "\n",
    "Endpoint: https://en.wikipedia.org/w/api.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting TV Data\n",
    "\n",
    "A few different kinds of Wikipedia pages we can use. \n",
    "\n",
    "1. [2015-16 United States network television schedule](https://en.wikipedia.org/wiki/2015%E2%80%9316_United_States_network_television_schedule)\n",
    "\n",
    "2. [2016 in American television](https://en.wikipedia.org/wiki/2016_in_American_television)\n",
    "\n",
    "3. [Category:2016 American television debuts](https://en.wikipedia.org/wiki/Category:2016_American_television_series_debuts)\n",
    "\n",
    "Let's use 1 and focus only on network television: ABC, CBS, The CW, Fox, and NBC.\n",
    "\n",
    "[comment]: <> (Should mention that JSON is more readable than HTML for machines and is equivalent to a Python dictionary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a few years, let's collect the show name, date aired, num seasons.\n",
    "\n",
    "We can use this category page, to get the pages that are like 1:\n",
    "\n",
    "[Category: United States primetime network television schedules](https://en.wikipedia.org/wiki/Category:United_States_primetime_network_television_schedules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 -- Get all the pages in the category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wikipedia_api_url = 'https://en.wikipedia.org/w/api.php'\n",
    "request_params = {'action': 'query',\n",
    "       'list': 'categorymembers',\n",
    "       'cmlimit': 500, # gonna assume no more than 500 categories\n",
    "       'cmtitle' : 'Category:United_States_primetime_network_television_schedules',\n",
    "       'format' : 'json'}\n",
    "response = requests.get(url=wikipedia_api_url, params=request_params)\n",
    "category_members = response.json()['query']['categorymembers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ns': 0,\n",
       "  'pageid': 35690173,\n",
       "  'title': '2012–13 United States network television schedule'},\n",
       " {'ns': 0,\n",
       "  'pageid': 38473731,\n",
       "  'title': '2013–14 United States network television schedule'},\n",
       " {'ns': 0,\n",
       "  'pageid': 40770098,\n",
       "  'title': '2014–15 United States network television schedule'},\n",
       " {'ns': 0,\n",
       "  'pageid': 44341616,\n",
       "  'title': '2015–16 United States network television schedule'},\n",
       " {'ns': 0,\n",
       "  'pageid': 47762863,\n",
       "  'title': '2016–17 United States network television schedule'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_members[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through gathering data for 2012-13 and then write some functions to gather data for the other years.\n",
    "\n",
    "Use the 'Inspect Element' feature of Firefox browser (or 'Developer Tools' in Chrome) to view the HTML and CSS for the elements you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 -- request page using Wikipedia API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikipedia_api_url = 'https://en.wikipedia.org/w/api.php'\n",
    "request_params = {'action': 'parse', # the kind of action we're doing\n",
    "                'pageid' : 35690173,   \n",
    "                'format' : 'json'}  # format of data returned\n",
    "response = requests.get(url=wikipedia_api_url, params=request_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 -- the text is just an html blob; we'll use beautifulsoup <br>\n",
    "to parse it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = BeautifulSoup(\n",
    "    response.json()['parse']['text']['*'],'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4 -- this will give us the table of programs on ABC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abc_table = parser.find('span', id='ABC').find_next('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 -- this will give us the name of new series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'666 Park Avenue'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_new_shows = abc_table.find_all('td')[1].find_all('li')\n",
    "abc_new_shows[0].find('a')['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6 -- parse tv show page and get num seasons **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikipedia_api_url = 'https://en.wikipedia.org/w/api.php'\n",
    "request_params = {'action': 'parse',                 # the kind of action we're doing\n",
    "                'page' : '20/20 (U.S. TV series)',   # title of page\n",
    "                'format' : 'json'}                   # format of data returned\n",
    "response = requests.get(url=wikipedia_api_url, params=request_params)\n",
    "\n",
    "parser = BeautifulSoup(\n",
    "    response.json()['parse']['text']['*'],'html.parser')\n",
    "table = parser.find(\n",
    "    \"table\", class_=\"infobox vevent\")\n",
    "table_row = table.find(\n",
    "    string=re.compile(\"of seasons\")).find_parent(\"tr\")\n",
    "num_seasons = table_row.find(\"td\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8 -- write functions to get all the data we want**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_show_data(title):\n",
    "    wikipedia_api_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    request_params = {'action': 'parse',  # the kind of action we're doing\n",
    "                'page' : title,   # title of page\n",
    "                'format' : 'json'}   # format of data returned\n",
    "    response = requests.get(url=wikipedia_api_url, params=request_params)\n",
    "\n",
    "    parser = BeautifulSoup(\n",
    "        response.json()['parse']['text']['*'],'html.parser')\n",
    "    table = parser.find(\"table\", class_=\"infobox vevent\")\n",
    "    if table is None:\n",
    "        num_seasons = None\n",
    "        release_date = None\n",
    "    else:\n",
    "        # get number of seasons\n",
    "        try:\n",
    "            table_row = table.find(\n",
    "                string=re.compile(\"of seasons\")).find_parent(\"tr\")\n",
    "            num_seasons = table_row.find(\"td\").text\n",
    "        except AttributeError as e: # we may not find the table\n",
    "            num_seasons = None\n",
    "        \n",
    "        # get release date\n",
    "        try:\n",
    "            release_date = table.find(\n",
    "                'span', class_='bday dtstart published updated').text\n",
    "        except AttributeError as e:\n",
    "            release_date = None\n",
    "\n",
    "    return {'title':title, \n",
    "            'num_seasons':num_seasons, \n",
    "            'release_date':release_date}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channels = ['ABC', 'CBS', 'The_CW', 'Fox', 'NBC']\n",
    "def get_shows(pageid):\n",
    "    \"\"\"Given a US network television schedule\"\"\"\n",
    "    request_params = {'action': 'parse',                      \n",
    "                'pageid' : pageid,   \n",
    "                'format' : 'json'}                          \n",
    "    response = requests.get(url=wikipedia_api_url, params=request_params)\n",
    "    parser = BeautifulSoup(\n",
    "        response.json()['parse']['text']['*'],'html.parser')\n",
    "    \n",
    "    # create list of data we're collecting\n",
    "    all_shows = []\n",
    "    for channel in channels:\n",
    "        channel_table = parser.find(\n",
    "            'span', id=channel).find_next('div')\n",
    "        new_shows = channel_table.find_all('td')[1].find_all('li')\n",
    "        for show in new_shows:\n",
    "            show_title = show.find('a')['title']\n",
    "            show_data = get_show_data(show_title)\n",
    "            show_data['channel'] = channel\n",
    "            all_shows.append(show_data)\n",
    "    return all_shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_data_1213 = get_shows(35690173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>num_seasons</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>666 Park Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-04-13</td>\n",
       "      <td>Bet on Your Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>Family Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>How to Live with Your Parents (For the Rest of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>Last Resort (U.S. TV series)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel num_seasons release_date  \\\n",
       "0     ABC           1   2012-09-30   \n",
       "1     ABC           2   2013-04-13   \n",
       "2     ABC           1   2013-05-01   \n",
       "3     ABC           1   2013-04-03   \n",
       "4     ABC           1   2012-09-27   \n",
       "\n",
       "                                               title  \n",
       "0                                    666 Park Avenue  \n",
       "1                                   Bet on Your Baby  \n",
       "2                                       Family Tools  \n",
       "3  How to Live with Your Parents (For the Rest of...  \n",
       "4                       Last Resort (U.S. TV series)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(show_data_1213)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we have some data. We would repeat this for all the seasons we want to get the shows from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some shows that have an original release date that is either not a valid date or is before 2012.  Let's convert invalidate dates to NaNs in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coerce to a valid date\n",
    "df['release_date'] = pd.to_datetime(\n",
    "    df['release_date'], infer_datetime_format=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>num_seasons</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The_CW</td>\n",
       "      <td>12</td>\n",
       "      <td>1998-08-05</td>\n",
       "      <td>Whose Line Is It Anyway? (U.S. TV series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fox</td>\n",
       "      <td>15</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>Fox College Football</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel num_seasons release_date                                      title\n",
       "32  The_CW          12   1998-08-05  Whose Line Is It Anyway? (U.S. TV series)\n",
       "35     Fox          15   1999-01-01                       Fox College Football"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# remove dates less than 2012\n",
    "df[df['release_date'] < datetime(year=2012, day=1, month=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[\n",
    " df['release_date'] < datetime(year=2012, day=1, month=1), 'release_date']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>num_seasons</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>666 Park Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-04-13</td>\n",
       "      <td>Bet on Your Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>Family Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>How to Live with Your Parents (For the Rest of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>Last Resort (U.S. TV series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>Malibu Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABC</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>Mistresses (U.S. TV series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABC</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Motive (TV series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABC</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>Nashville (2012 TV series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABC</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-09-26</td>\n",
       "      <td>The Neighbors (2012 TV series)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel num_seasons release_date  \\\n",
       "0     ABC           1   2012-09-30   \n",
       "1     ABC           2   2013-04-13   \n",
       "2     ABC           1   2013-05-01   \n",
       "3     ABC           1   2013-04-03   \n",
       "4     ABC           1   2012-09-27   \n",
       "5     ABC           1   2012-11-02   \n",
       "6     ABC           4   2013-06-03   \n",
       "7     ABC           4   2013-02-03   \n",
       "8     ABC           4   2012-10-10   \n",
       "9     ABC           2   2012-09-26   \n",
       "\n",
       "                                               title  \n",
       "0                                    666 Park Avenue  \n",
       "1                                   Bet on Your Baby  \n",
       "2                                       Family Tools  \n",
       "3  How to Live with Your Parents (For the Rest of...  \n",
       "4                       Last Resort (U.S. TV series)  \n",
       "5                                     Malibu Country  \n",
       "6                        Mistresses (U.S. TV series)  \n",
       "7                                 Motive (TV series)  \n",
       "8                         Nashville (2012 TV series)  \n",
       "9                     The Neighbors (2012 TV series)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the data to a file to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('tv_show_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
